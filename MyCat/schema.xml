<?xml version="1.0"?>
<!DOCTYPE mycat:schema SYSTEM "schema.dtd">
<mycat:schema xmlns:mycat="http://io.mycat/">
	<!-- 如果需要切换 9066 执行切换数据源命令:switch @@datasource blog:0;blog 是dataHost 名字,后面的是writerHost 编号默认从0开始 -->

	<!-- schema:逻辑库配置 -->
	<!-- name:逻辑库名称 -->
	<!-- checkSQLschema:检查逻辑库存在与否 -->
	<!-- sqlMaxLimit:数据返回最大条数 -->
	<schema name="TESTDB" checkSQLschema="true" sqlMaxLimit="100" randomDataNode="dn1">
		<!-- table:表相关配置 -->
		<!-- name:mycat中的表,非真实数据库表,在mycat中创建表的时候会同时向对应的数据库中创建表 -->
		<!-- primaryKey:表主键字段 -->
		<!-- dataNode:数据库分片逻辑节点 -->
		<!-- rule:表分片规则 -->
		<!-- autoIncrement:主键自增策略 -->
		<!-- fetchStoreNodeByJdbc:启用ER表使用JDBC方式获取DataNode,主要用来处理join -->
		<!-- splitTableNames:启用table->name属性使用逗号分割配置多个表,即多个表使用这个配置 -->
		<table name="table1" primaryKey="id" dataNode="dn1,dn2" rule="sharding-by-intfile" autoIncrement="true" fetchStoreNodeByJdbc="true">
			<!-- 子表,主要用于关联查询:joinKey:子表和主表进行关联的子表的字段;parentKey:子表和主表进行关联的主表的字段 -->
			<!-- 主要用于ER表,防止跨分片联表,可以递归配置,子表的路由依赖于父表,根据父表的数据位置存储 -->
			<childTable name="table1_child" primaryKey="id" joinKey="table1_id" parentKey="id">
				<childTable name="table1_child_child" primaryKey="id" joinKey="table1_child_id" parentKey="id"></childTable>
			</childTable>
		</table>
		<!-- <table name="oc_call" primaryKey="ID" dataNode="dn1$0-743" rule="latest-month-calldate" /> -->

		<!-- 全局表,dn1和dn2中都需要建表,如字典表等.增删改会在所有分片界定执行,查询会随机选择一个节点 -->
		<table name="table2" primaryKey="id" dataNode="dn$1-2" type="global" />

		<!-- 按天分片事例 -->
		<table name="table3" primaryKey="id" dataNode="dn$1-2" rule="sharding-by-date" />

		<!-- 按文件内容进行枚举分片 -->
		<table name="table4" primaryKey="id" dataNode="dn$1-2" rule="sharding-by-intfile" />

		<!-- 按范围进行分片 -->
		<table name="table5" primaryKey="id" dataNode="dn$1-2" rule="auto-sharding-long" />

		<!-- 按取模值进行分片,dataNode有2个,mod-long的分片个数就只能有2个,除非设置默认数据库,取模失败的存储到默认数据库 -->
		<table name="table5" primaryKey="id" dataNode="dn$1-2" rule="mod-long" />
	</schema>
	<!-- <dataNode name="dn1$0-743" dataHost="localhost1" database="db$0-743" /> -->
	<dataNode name="dn1" dataHost="localhost1" database="db1" />
	<dataNode name="dn2" dataHost="localhost2" database="db1" />

	<!-- 只做读写分离不做数据切分的配置,只需要配置默认分片节点,dataNode="dn1"即可,不需要配置所有的表 -->
	<dataHost name="localhost1" maxCon="1000" minCon="10" balance="0" writeType="0" dbType="mysql" dbDriver="jdbc" switchType="1"  slaveThreshold="100">
		<heartbeat>select user()</heartbeat>
		<!-- can have multi write hosts -->
		<writeHost host="hostM1" url="jdbc:mysql://localhost:3306" user="root" password="root"></writeHost>
		<!-- <writeHost host="hostM2" url="localhost:3316" user="root" password="123456"/> -->
	</dataHost>
	<dataHost name="localhost2" maxCon="1000" minCon="10" balance="0" writeType="0" dbType="mysql" dbDriver="jdbc" switchType="1"  slaveThreshold="100">
		<heartbeat>select user()</heartbeat>
		<writeHost host="hostM2" url="jdbc:mysql://localhost:3306" user="root" password="root"></writeHost>
	</dataHost>


	<!-- 主从配置:在dataHost中配置多个writeHost,默认以配置顺序为主,第一个为主库,后面为从库,可以有多个,切换类型writeType=1或者2,0不切换 -->
	<!-- 如果主挂掉,根据配置顺序选择新的主.具体主的为那个记录在 dnindex.properties 中 -->
	<dataHost name="blog" maxCon="100" minCon="10" balance="1"  writeType="0" dbType="mysql" dbDriver="native" switchType="1">
		<heartbeat>select 1</heartbeat>
		<writeHost host="master" url="127.0.0.1:3306" user="root" password="123456"></writeHost>
		<writeHost host="slave" url="salveip:3306" user="root" password="123456"></writeHost>
	</dataHost>

	<!--
		<dataHost name="sequoiadb1" maxCon="1000" minCon="1" balance="0" dbType="sequoiadb" dbDriver="jdbc">
		<heartbeat> 		</heartbeat>
		 <writeHost host="hostM1" url="sequoiadb://1426587161.dbaas.sequoialab.net:11920/SAMPLE" user="jifeng" 	password="jifeng"></writeHost>
		 </dataHost>

	  <dataHost name="oracle1" maxCon="1000" minCon="1" balance="0" writeType="0" 	dbType="oracle" dbDriver="jdbc"> <heartbeat>select 1 from dual</heartbeat>
		<connectionInitSql>alter session set nls_date_format='yyyy-mm-dd hh24:mi:ss'</connectionInitSql>
		<writeHost host="hostM1" url="jdbc:oracle:thin:@127.0.0.1:1521:nange" user="base" 	password="123456" > </writeHost> </dataHost>

		<dataHost name="jdbchost" maxCon="1000" 	minCon="1" balance="0" writeType="0" dbType="mongodb" dbDriver="jdbc">
		<heartbeat>select 	user()</heartbeat>
		<writeHost host="hostM" url="mongodb://192.168.0.99/test" user="admin" password="123456" ></writeHost> </dataHost>

		<dataHost name="sparksql" maxCon="1000" minCon="1" balance="0" dbType="spark" dbDriver="jdbc">
		<heartbeat> </heartbeat>
		 <writeHost host="hostM1" url="jdbc:hive2://feng01:10000" user="jifeng" 	password="jifeng"></writeHost> </dataHost> -->

	<!-- <dataHost name="jdbchost" maxCon="1000" minCon="10" balance="0" dbType="mysql"
		dbDriver="jdbc"> <heartbeat>select user()</heartbeat> <writeHost host="hostM1"
		url="jdbc:mysql://localhost:3306" user="root" password="123456"> </writeHost>
		</dataHost> -->
</mycat:schema>